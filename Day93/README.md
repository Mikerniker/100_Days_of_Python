# Day 93 Professional Portfolio Project: Custom Web Scraper


https://github.com/user-attachments/assets/22f97cbf-5a40-480f-8e52-de1bfb4e9e6c



## Overview

- Topics: Python, API (Sheety), Pandas

### The challenge

- Build a custom web scraper to collect data on things that you are interested in.
 
### Links

- Solution URL: [Custom Web Scraper](https://github.com/Mikerniker/100_Days_of_Python/tree/main/Day93)

## Reflection
**Approach, Challenges, Learnings, and Future Improvements:** 
I began by using BeautifulSoup to scrape the website for chocolates produced in my country. Afterward, instead of manually building a CSV file, I reviewed using APIs with Sheety to automate the process and send the data via an API POST request.
One of the main challenges was identifying the correct HTML elements to scrape with BeautifulSoup. I also faced some minor issues, like typos, that slowed down progress. Additionally, managing and organizing the scraped data efficiently required reviewing my use of the pandas library. Once I got the hang of Sheety's API and made successful POST requests, adding the data became straightforward. 
For future projects, I’d consider exploring alternative data collection methods, such as using Selenium.
I’d also possibly explore saving the data in alternative formats (like CSV, JSON, or databases).

## References
- [Table](https://stackoverflow.com/questions/2010481/how-do-you-get-all-the-rows-from-a-particular-table-using-beautifulsoup)
- [Getting a Table](https://stackoverflow.com/questions/20522820/how-to-get-tbody-from-table-from-python-beautiful-soup) 
